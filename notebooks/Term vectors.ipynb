{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                       \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                           \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.lucene:lucene-core:7.2.1`\n",
    "import $ivy.`org.apache.lucene:lucene-queries:7.2.1`\n",
    "import $ivy.`org.apache.lucene:lucene-queryparser:7.2.1`\n",
    "import $ivy.`org.apache.lucene:lucene-analyzers-common:7.2.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.lucene.analysis.standard.StandardAnalyzer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.lucene.document._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.lucene.index._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.lucene.store.RAMDirectory\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.lucene.util.BytesRef\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.lucene.analysis.standard.StandardAnalyzer\n",
    "import org.apache.lucene.document._\n",
    "import org.apache.lucene.index._\n",
    "import org.apache.lucene.store.RAMDirectory\n",
    "import org.apache.lucene.util.BytesRef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this to convert some nasty iterator-like Java objects to Scala collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtoScalaStream\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toScalaStream[T](iter: {def next(): T}): Stream[T] = {\n",
    "  val value = iter.next()\n",
    "  if (value == null) Stream.empty[T]\n",
    "  else value #:: toScalaStream(iter)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The usual setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36manalyzer\u001b[39m: \u001b[32mStandardAnalyzer\u001b[39m = org.apache.lucene.analysis.standard.StandardAnalyzer@18eb897b\n",
       "\u001b[36mindexWriter\u001b[39m: \u001b[32mIndexWriter\u001b[39m = org.apache.lucene.index.IndexWriter@55b71374"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val analyzer = new StandardAnalyzer()\n",
    "val indexWriter = new IndexWriter(\n",
    "  new RAMDirectory(),\n",
    "  new IndexWriterConfig(analyzer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtextFieldType\u001b[39m: \u001b[32mFieldType\u001b[39m = stored,indexed,tokenized,termVector"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val textFieldType = new FieldType()\n",
    "\n",
    "textFieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "textFieldType.setTokenized(true)\n",
    "textFieldType.setStored(true)\n",
    "textFieldType.setStoreTermVectors(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres5\u001b[39m: \u001b[32mDocValuesType\u001b[39m = NONE"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFieldType.docValuesType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcontents\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m\"Humpty Dumpty sat on a wall,\"\u001b[39m,\n",
       "  \u001b[32m\"Humpty Dumpty had a great fall.\"\u001b[39m,\n",
       "  \u001b[32m\"All the king's horses and all the king's men\"\u001b[39m,\n",
       "  \u001b[32m\"Couldn't put Humpty together again.\"\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val contents = Array(\n",
    "  \"Humpty Dumpty sat on a wall,\",\n",
    "  \"Humpty Dumpty had a great fall.\",\n",
    "  \"All the king's horses and all the king's men\",\n",
    "  \"Couldn't put Humpty together again.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres7_1\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m7L\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents.foreach { content =>\n",
    "  val doc = new Document();\n",
    "  val textField = new Field(\"content\", content, textFieldType)\n",
    "  \n",
    "  doc.add(textField)\n",
    "  indexWriter.addDocument(doc)\n",
    "}\n",
    "\n",
    "indexWriter.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mindexReader\u001b[39m: \u001b[32mDirectoryReader\u001b[39m = StandardDirectoryReader(segments_1:4 _0(7.2.1):c4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val indexReader = DirectoryReader.open(\n",
    "  indexWriter.getDirectory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0\n",
      "dumpty humpty sat wall \n",
      "Document 1\n",
      "dumpty fall great had humpty \n",
      "Document 2\n",
      "all horses king's men \n",
      "Document 3\n",
      "again couldn't humpty put together \n"
     ]
    }
   ],
   "source": [
    "(0 until indexReader.maxDoc) foreach { i =>\n",
    "  \n",
    "  val terms = indexReader.getTermVector(i, \"content\")\n",
    "  val termsIterator = terms.iterator()\n",
    "  val termsStream = toScalaStream(terms.iterator()).map(_.utf8ToString())\n",
    "  println(s\"Document $i\")\n",
    "  termsStream.foreach { term =>\n",
    "    print(term + \" \")\n",
    "  }\n",
    "  println()\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
